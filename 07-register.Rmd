# Register-Based Survival Data Models
\index{register data}
```{r settings7, echo = FALSE, include = FALSE}
knitr::opts_chunk$set(comment = "", message = FALSE, echo = TRUE, cache = FALSE)
options(width = 70, digits = 7, warn = -1) ## NOTE: No warnings!
```

During the last couple of decades, huge data bases with poulation data have 
popped up around the world. They are great sources of information in demographic 
and statistical research, but their sizes creates challenges for the statistical 
tools we traditionally use in the demographic analyses.

We distinguish between data sources with individual content and sources with 
tabular data. In both cases, however, we will end up analyzing tables, so we 
start by describing methods for analyzing tables.

Finally, in this chapter, we show how to combine the technique with 
communal covariates\index{communal covariates} 
with tabulating data. The problem we solve is that the creation of an individual-based
data set with communal covariates usually leads to uncomfortably large data sets.
Tabulation is often a good solution to this problem.  

## Tabular Data
\index{tabular data}
National statistical agencies produce statistics describing the population year 
by year, in terms of population size by age and sex, number of births by mother's
age and sex of the newborn, number of deaths by age and sex, and so on. In the
package **eha**, there are two data sets taken from [Statistics Sweden](https://scb.se),
`swepop` and `swedeaths`.

The content of `swepop` is shown in Table \@ref(tab:swepop7) (first five rows out
of 10504 rows in total).

\tiny
```{r swepop7, echo = FALSE, message = FALSE}
library(eha)
library(kableExtra)
sw <- swepop
sw$id <- NULL
rownames(sw) <- 1:NROW(sw)
##kbl(head(sw, 5), booktabs = TRUE, caption = "First rows of 'swepop'.",
  ##              label = "swepop7")
source("R/tbl.R")
tbl(head(sw, 5), caption = "First rows of swepop.")
```
\normalsize
It contains the average Swedish population size by year, age, and sex, where age 
is grouped into one-year classes, but the highest age class, labelled 100, is in fact 
"ages 100 and above". The original table gives the population sizes at the end of each year,
but here we have calculated an average size over the year in question by taking the mean
of the actual value and the corresponding value from the previous year. The population size 
can in this way be used as a proxy for, prediction of,  "total time at risk" or *exposure*. 

The content of `swedeaths` (first five rows) is shown in Table \@ref(tab:swedeaths7).

```{r swedeaths7, echo = FALSE}
deaths <- swedeaths
deaths$id <- NULL
rownames(deaths) <- 1:NROW(deaths)
tbl(head(deaths, 5), caption ="First rows of swedeaths.")
```

The `(age, sex, year)` columns in the two data frames are identical, so we can 
create a suitable data frame for analysis simply by putting `swedeaths$deaths`
into the data frame `swepop` and rename it to `sw`. The first rows of `sw` are
shown Table \@ref(tab:sw7).

```{r sw7, echo = FALSE}
sw$deaths <- deaths$deaths
kbl(head(sw, 5), booktabs = TRUE, caption = "First rows of combined data frame.")
```

The response variable in our analysis is two-dimensional: `(deaths, pop)`, 
which is on an "occurrence/exposure" form, suitable for an analysis with the 
function `tpchreg`.\index{Functions!\fun{tpchreg}} The result is a *proportional hazards* analysis with 
the assumption of a piecewise constant baseline hazard function:

```{r preptpchtab7}
sw$year.1995 <- sw$year - 1995
system.time(fit <- tpchreg(oe(deaths, pop) ~ sex + year.1995, 
               time = age, last = 101, data = sw))
```

Note several things here:

1.   The fitting procedure is wrapped in a call to the function `system.time`. 
This results in the first report headed "user  system  elapsed", giving the time
in seconds for the whole operation ("elapsed"), split up by "user" (the time spent
with our call) and "system" (time spent by the operating system, for instance 
reading, writing and organizing the user operation). The interesting value for us 
is that the total elapsed time was around half a second. Quite OK for a
proportional hazards regression analysis involving `r sum(sw$deaths)` events.


2.   The response is `oe(deaths, pop)` where the function name `oe` 
\index{Functions!\fun{oe}} is short for "occurrence/exposure".

3.   All covariates have a *reference value*. For factors with the default coding,
the reference category is given, but for continuous covariates we need to specify
it, if we are not satisfied with the default value *zero*. In the case with the 
covariate `year`, we are certainly *not* satisfied with zero as reference point, 
so we choose a suitable value in the range of the observed values. This is done in
practice by *subtracting* the reference value from the corresponding variable, 
forming `year - 1995` in our case. In the output below, this will only affect the value
of *Restricted mean survival*, which is calculated for a "reference individual",
in this case *a woman living her life during the year 1995*. There are not many such 
women, of course, what we are doing here is comparing periods, not cohorts.

4.   Note the argument `last = 101`. Since we are fitting a survival distribution
that is unbounded in time, we should specify the range for our data. The lower 
limit is given by `min(age)` (the argument `time`), but there is no natural upper limit.
The choice of the value for `last` do not affect parameter estimates and general 
conclusions, it only affects plots in the extreme of the right tail (slightly). 


```{r tpchtab7, results = 'asis', echo = FALSE}
source("R/fit.out.R")
fit.out(fit, caption = "Swedish mortality, 1968--2020.", 
        label = "tpchtab7")
```

Note the "Restr. mean survival": It gives the expected remaining life 
*at birth* for a *woman* in the *year 1995* (the reference values).

The graph of the baseline hazard function ("age-specific mortality") is shown in 
Figure \@ref(fig:base7).

```{r base7, fig.cap = "Baseline hazard function, women 1995. Model based.", echo = FALSE}
par(las = 1)
plot(fit, fn = "haz", main = "", xlab = "Age", ylab = "Mortality", col = "red")
abline(h = 0)
abline(v = summary(fit)$rmean, lty = 3)
text(78, 0.3, "Expected life at birth", srt = 90, cex = 0.8)
```

Apart from the first year of life, mortality seems to be practically zero the first
forty years of life, and then exponentially increasing with age.

This is simple enough, but some questions remain unanswered. First, the model 
assumes proportional hazards, implying for instance that male mortality is around 
50 per cent higher than female in all ages. It is fairly simple to organize a 
formal test of the proportionality assumption, but it is close to meaningless, 
because of the huge amount of data (almost five million deaths, "all" null
hypotheses will be rejected). A better 
alternative is to do it graphically by *stratifying* on `sex`.

```{r base27, fig.cap = "Baseline hazard function, women and men 1995.", echo = FALSE}
par(las = 1)
fit2 <- tpchreg(oe(deaths, pop) ~ strata(sex) + I(year - 1995), 
               time = age, last = 101, data = sw)
sf2 <- summary(fit2)
plot(fit2, fn = "haz", main = "", xlab = "Age", ylab = "Mortality", 
     col = c("red", "blue"))
abline(h = 0)
abline(v = sf2$rmean, lty = 3, col = c("red", "blue"))
```

Due to the extremely low mortality in early ages, Figure \@ref(fig:base27) is 
quite non-informative. We try the same plot on a log scale, see Figure \@ref(fig:base37).

```{r base37, fig.cap = "Baseline hazard functions, women and men 1995. Log scale.", echo = FALSE}
par(las = 1, cex = 0.9)
plot(fit2, fn = "haz", main = "", xlab = "Age", ylab = "Log mortality", 
     col = c("red", "blue"), log = "y")
```

The female advantage is largest in early adulthood, after which it slowly decreases.
An even clearier picture is shown in Figure \@ref(fig:base47), where the ratio of 
male vs. female mortality is plotted.

```{r base47, fig.cap = "Hazard ratio by age, men vs. women 1995.", echo = FALSE}
par(las = 1)
x <- seq(0, 100)
y <- fit2$hazards[2, ] / fit2$hazards[1, ]
plot(x, y, main = "", xlab = "Age", ylab = "Hazard ratio", 
     col = c("blue"), type = "l", ylim = c(1, 3))
abline(h = 1)
```

This graph gives the clearest picture of the relative differences in mortality 
over the life span. We see, somewhat unexpectedly, that the drop in the ratio 
is broken around  age 50, and then continues after age 70. This is not clearly 
visible in the earlier figures. A possible explanation is that the age interval
20--50 approximately coincides with women's fertility period, that is, during
this period, the female mortality advantage decreases more than pure age motivates. 

This pattern may change over the time period 1969--2020. We split the 
data by year into quarters in order to check this. The rise after age 50 seems to vanish with time, according to Figure \@ref(fig:quarters7).

```{r quarters7, fig.cap = "Baseline hazard ratios, men vs. women by time period.", echo = FALSE}
oldpar <- par(mfrow = c(2, 2))
start <- 1969
par(las = 1)
for (i in 1:4){
    slut <- start + 12
    swx <- sw[sw$year %in% start:slut, ]
    fit2 <- tpchreg(oe(deaths, pop) ~ strata(sex) + I(year - start + 7), 
               time = age, last = 101, data = swx)
    y <- fit2$hazards[2, ] / fit2$hazards[1, ]
    plot(x, y, main = "", xlab = iv(start, slut), ylab = "Hazard ratio", 
         col = "blue", type = "l", ylim = c(1, 3))
    abline(h = 1)
    start <- slut + 1
}
par(oldpar)
```


Finally, we investigate the development of expected life ($e_0$) over time, see Figure
\@ref(fig:e07).

```{r e07, fig.cap = "Expected life at birth by sex and year (period data).", echo = FALSE}
fem <- numeric(52)
mal <- numeric(52)
i <- 0
for (year in 1969:2020){
    i <- i + 1
    fit <- tpchreg(oe(deaths, pop) ~ strata(sex), 
                   data = sw[sw$year == year, ],
                   time = age, last = 101)
    x <- summary(fit)
    fem[i] <- x$rmean[1]
    mal[i] <- x$rmean[2]
}
att <- c(1969, 1981, 1994, 2007, 2020)
plot(1969:2020, fem, type = "b", col = "red", ylim = c(70, 85), 
     ylab = "Age", xlab = "Year", axes = FALSE)
axis(1, at = att)
axis(2, las = 1)
box()
lines(1969:2020, mal, type = "b", col = "blue", pch = "+")
text(1990, 82, "Women", col = "red")
text(1990, 73, "Men", col = "blue")
abline(h = c(75, 80, 85), lty = 3)
abline(v = att, lty = 3)
```

The difference in longevity between women and men is slowly decreasing over the 
time period. Also note the values in the last two years: Mortality in Sweden was
unexpectedly low in the year 2019, resulting in high values of expected life, but in 
2020, the pandemic virus *covid-19*\index{covid-19} struck, and the expected life dropped by
around five months for women and almost nine months for men, compared to 2019.

## Individual Data

The analysis of individual survival data is what the rest of this book is all 
about, so what is new here? The answer lies in the *size* of the data sets, 
that is, the number of individuals is *huge*. 

As an example, we have mortality data consisting of all Swedish citizens aged
30 and above for the years 2001--2013. It may be described as yearly censuses, where 
all Swedish persons alive at December 31 the specific year are registered together 
with vital information. It starts with register data of the form shown in 
Table \@ref(tab:vitalform7).

```{r vitalform7, echo = FALSE}
source("R/tbl.R")
rl <- readRDS("rawlis.rds")
rl$birthdate <- toDate(rl$birthdate)
##rl$region <- rl$municipality
##rl$municipality <- NULL
rownames(rl) <- 1:4
##kbl(rl, booktabs = TRUE, caption = "Register data, Sweden December 31, 2001.") %>%
  ##   kable_styling(font_size = 10)
tbl(rl, caption = "Register data, Sweden December 31, 2001.", fs = 9)
```

The variables are

*   **id** A unique id number, which allows us to link information from different
sources (and years) to one individual.
*   **year** The present year, 2001, $\ldots$, 2013.
*   **sex**  Female or male.
*   **birthdate** A constructed variable. Due to integrity reasons, birth time information
is only given in the form of year and quarter of the year. So the *birthdate* is created
by year and the first quarter is represented by the decimal places ".125" (equal roughly
to February 15), the second quarter is ".375", third ".625", and finally the fourth 
quarter is represented by ".875"). The birthdate will be off by plus or minus one 
month and a half, which is deemed to be a good enough precision concerning our 
analysis of adult mortality.
*   **deathdate** Is given by day in the sources. The missing value symbol (*NA*) 
is given to those who are not registered as dead before January 1, 2014. Each date 
is converted to decimal form.
*   **civst, ses, region** Information about *civil status*, 
*socioeconomic status*, and *geographic area*, respectively.

From this yearly information, survival data is created by following each individual 
one year ahead, until the next "census". Age at start, `enter`, is calculated by 
subtracting `birthdate` from the date of presence, `year + 1`. For an individual 
with a deathdate less than or equal to `enter + 1 = year + 2`, the variable `exit` is 
calculated as `deathdate - birthdate` and the variable `event` is set equal to one, otherwise 
`exit = enter + 1` and `event = 0`, a censored observation.

The result of this is shown for the same individuals as above in 
Table \@ref(tab:workedform7), with three covariates omitted in order to save space.

```{r workedform7, echo = FALSE}
wl <- readRDS("worklis.rds")
##wl$region <- wl$municipality # Change name.
##wl$municipality <- NULL
rownames(wl) <- 1:4
##kbl(wl[, c("id", "year", "enter", "exit", "event")], booktabs = TRUE,
##caption = "Constructed data, Sweden December 31, 2001.") %>%
##     kable_styling(font_size = 10)
tbl(wl[, -(6:8)], caption = "Constructed data, Sweden December 31, 2001.")
```

This file from the year 2001 (covering the year 2002!) contains *5.8 million* individuals
and 92 thousand deaths. To perform a Cox regression on such massive data sets 
(and there are thirteen of them) is time, software, 
and hardware consuming, but there is a simple remedy: Make tables and fit 
*piecewise constant proportional hazards* (pch) models.

This is done with the aid of the `eha` function `toTpch`. We decide to choose the pch
model as constant over five-year intervals 30--35, 35--40, $\ldots$, 100--105, 
and we replace birthdate
by birth year (more suitable as a covariate) and call it `cohort`. It is done 
with the aid of the R function `floor`:

```
lisa2001$cohort <- floor(lisa2001$birthdate)
```
The function `floor` simply removes the decimals from a positive number.
Then we apply the function `toTpch`:

```
listab2001 <- toTpch(Surv(enter, exit, event) ~ sex + cohort + year + 
                                                civst + region + ses,
                     data = lisa2001, 
                     cuts = c(seq(30, 100, by = 5), 105))
```

```{r maketableread7, echo = FALSE, comment=""}
lisa2001 <- readRDS("mytables/listab2001.rds")
lisa2001$region <- lisa2001$municipality
lisa2001$municipality <- NULL
##kableExtra::kbl(head(lisa2001, 4), booktabs = TRUE, digits = 4,
  ##              caption = "Mortality in ages above 30, Sweden 2002 (year = 2001).", 
    ##            label = "maketableread7") %>%
##    kable_styling(font_size = 10)
lhead <- head(lisa2001, 5)
lhead$age <- en(lhead$age)
tbl(lhead, caption = "Mortality in ages above 30, Sweden 2002 (year = 2001).", fs = 9)
```

The result is shown in 
Table \@ref(tab:maketableread7) (four first rows) 
which is a table with  `r nrow(lisa2001)` rows. That is, one row for each unique 
combination of the six covariates for each interval, empty combinations excluded. Note the three created
variables, `event` which is the total number of events for each combination of covariates, 
`exposure`, which is the total time at risk for each corresponding combination, and `age`,
which is the age intervals with constant hazard.


In the survival analysis, the pair `(event, exposure)` is the *response*, and 
behind the scene, *Poisson regression* is performed with `event` as response and 
`log(exposure)` as *offset*.

Finally, thirteen similar tables are created (one for each year 2001--2013) and 
merged, using the **R** command `rbind`.



```{r sumres7, echo = FALSE}
##listab <- readRDS("~/Forskning/Blog/mytables/listab2001.rds")
##for (y in 2002:2013){
##    fnam <- paste("~/Forskning/Blog/mytables/listab", y, ".rds", sep = "")
##    xx <- readRDS(fnam)
##    listab <- rbind(listab, xx)
##}
listab <- readRDS("mytables/listab.rds")
listab$ses <- relevel(listab$ses, ref = "worker")
listab$civst <- relevel(listab$civst, ref = "married")
levels(listab$age)[15] <- "100-105"
listab$cohort <- NULL
```

A summary of the result gives

*   Number of records: `r NROW(listab)`.
*   Number of deaths: `r round(sum(listab$event) / 1000000, 2)` millions.
*   Total time at risk: `r round(sum(listab$exposure / 1000000), 2)` million years.

Now this data set is conveniently analyzed with the aid of the function `tpchreg` 
in `eha`. An example:

```{r runtab7, comment = "", echo = TRUE}
listab$year <- listab$year - 2000 # Center!
list2 <- aggregate(cbind(event, exposure) ~ sex + civst + ses + 
                       year + age, FUN = sum, data = listab)
fit <- tpchreg(oe(event, exposure) ~ strata(sex) + civst + ses + 
                   year, data = list2, time = age, last = 105)
xx <- summary(fit)
emen <- round(xx$rmean[1], 2)
ewomen <- round(xx$rmean[2], 2)
```

```{r runtable77, results = "asis", echo = FALSE}
##if (knitr::is_latex_output()){
##    fit.ltx <- tpchreg(oe(event, exposure) ~ strata(sex) + civst + ses + 
##                   year, data = list2, time = age, last = 105)
##    dr = drop1(fit.ltx, test = "Chisq")[-2, ] # A hack!!
##    ltx(summary(fit.ltx), dr = dr, 
##        caption = "Mortality in Sweden 2002-2014, ages 30 and above.", 
##        label = "runtable7")
##}
fit.out(fit, 
        caption = "Mortality in Sweden 2002--2014, ages 30 and above.", 
        label = "runtable77")
```

```{r runtable7, echo = FALSE, eval = FALSE}
if (knitr::is_html_output()) print(xx)
```

The result is shown in Table \@ref(tab:runtable77).

We note a couple of things here:

1.   The data frame `listab` contains `r NROW(listab)` records, and the execution time 
of a Poisson regression might take a long time. Since we did not use the covariates 
`region` (a factor with 25 levels) and `cohort` (92 levels), we could aggregate over 
these variables which resulted 
in the data frame `list2` with only `r NROW(list2)` records. This cuts down 
computing time by approximately 99 per cent, or to 0.17 seconds from 17 seconds. 
The results are not affected by this. Also note the similarity between 
the `formula` arguments of the two functions `aggregate` and `tpchreg`. 
The differences are that in `aggregate`, the function `cbind` is used instead 
of `oe`, and `strata()` is left out.

2.   All *p*-values are effectively zero, a consequence of of the huge amount of data.
It is also reasonable to claim that this constitutes a *total investigation*, and 
therefore *p*-values are meaningless.

3. The restricted mean survival 
*at age 30* for a *married worker* in the *year 2002* is `r emen` 
years for men and `r ewomen` years for women,
that is, the expected age of death is `r 30 + emen` years for 
men and `r 30 + ewomen` years for women alive at 30.

A graph of the conditional survival functions is shown in Figure \@ref(fig:wbhaz7).

```{r wbhaz7, fig.cap = "Survival above 30, males and females, married worker, Sweden 2002.", echo = FALSE, fig.height = 3.5}
par(las = 1)
plot(fit, fn = "sur", col = c("blue", "red"), lty = c(1, 2), xlab = "Age", 
     main = "", printLegend = "left")
axis(1, at = seq(30, 100, by = 10))
##axis(2, las = 1)
##box()
abline(h = 0)
```

## Communal Covariates and Tabulation

The application of the function `make.communal` (see previous chapter) 
\index{Functions!\fun{make.communal}} will often result in impractically 
large data sets, and it is recommended to combine it with the tabulation technique
suggested in this chapter. We illustrate it with an investigation of the influence of
weather conditions on mortality for two time periods, 1901--1950 and 1990--2014.
In the first case focus is on the effect of low temperature on mortality, and the
second case has the opposite focus, is an extremely hot summer bad for survival.
The geographical area under study is the Swedish town Umeå, situated at the Gulf 
of Bothnia on the latitude 64 degrees north. 

### Temperature and mortality, Umeå 1901--1950

Daily temperature data from
[SMHI](https://www.smhi.se/data/meteorologi/ladda-ner-meteorologiska-observationer#param=airtemperatureInstant,stations=all,stationid=140500) for central Umeå, starting at November 1, 1858 and ending at September 30, 
1979 (this particular weather station was replaced at this last date)
are used together with population data from Umeå.
Since we attempt to match these data to population data for the time period 
January 1, 1901--December 31, 1950, we
 cut the temperature data to the same time period. See Table \@ref(tab:plottemp).


```{r gettemp}
library(eha)
temp <- read.table("~/Forskning/Data/ume_temp.csv", 
                   header = TRUE,
                   skip = 10, sep = ",")[, 1:3]
## We need only the first three columns
names(temp) <- c("date", "time", "temp")

temp$date <- as.Date(temp$date)
temp$year <- as.numeric(format(temp$date, "%Y"))
temp$month <- as.numeric(format(temp$date, "%m"))
temp <- temp[order(temp$date, temp$time), ]
temp$quarter <- quarters(temp$date)
temp <- temp[temp$year %in% 1901:1950, ]
##

temp$time <- as.factor(temp$time)
temp$quarter <- as.factor(temp$quarter)
```

```{r plottemp, echo = FALSE}
source("~/Documents/EHAR2/R/tbl.R")
ltemp <- head(temp, 10)
ltemp$temp <- um(ltemp$temp)
tbl(ltemp, fs = 11, caption = "Temperature in Umeå, 1901--1950.") 
## fs stands for 'font size'.
rr <- range(temp$temp)
```

Apparently, there are three measurements each day, and the temperature range is
(`r um(rr[1])`, `r rr[2]`) degrees Celsius. 
The variables *year*, *month*, and *quarter* were extracted from the *date*. 

We extract population data for Umeå, 1 Jan 1901 to 31 Dec 1950, and include all 
ages between 15 and 100, see Table \@ref(tab:popdata7) for the first few rows.

```{r popdata7, echo = FALSE}
library(skum)
ume <- obs[obs$region == "ume", ]
ume$event <- (ume$sluttyp == 2)
ume <- cal.window(ume, c(1901, 1951))
ume <- age.window(ume, c(15, 101))
ume$socStatus[is.na(ume$socStatus)] <- "low"
ume <- ume[, c("id", "sex", "birthdate", "enter", "exit", "event", "socStatus")]
##ume$urban <- ume$ortnmn == "UMEÅ"
##ume$ortnmn <- NULL
noll <- ume$enter >= ume$exit
ume$enter[noll] <- ume$enter[noll] - 0.001 # Fix zero length spells
ume$enter <- round(ume$enter, 3)
ume$exit <- round(ume$exit, 3)
show <- head(ume, 3)
show$birthdate <- toDate(show$birthdate)
tbl(show, fs = 11, 
    caption = "Umeå data, ages 15--100, time period 1901--1950.")
```

There are `r NROW(ume)` records describing `r length(unique(ume$id))` individuals in this selection.
In order to simplify the presentation, only two covariates, `sex` and `urban`, are included.

The first question is what to do with the temperature measurements. They span 
50 years, with mostly three measurements per day. In this first analysis we 
focus on the effect on mortality of *low* temperatures, so we start by taking the 
maximum of daily temperatures, then minimum over month. We thus end
up with one measurement per month and year, in total 600 measurements.

Start by finding the *maximum* value each day, result in Table \@ref(tab:maxtemp7).

```{r maxtemp7}
idx <- with(temp, tapply(date, date))
maxtemp <- with(temp, tapply(temp, date, max))
temp$maxtemp <- maxtemp[idx]
## Reduce to one measurement per day:
mtemp <- temp[!duplicated(temp$date), 
              c("date", "maxtemp", "month", "quarter", "year")]
rownames(mtemp) <- 1:NROW(mtemp)
lmtemp <- head(mtemp, 3)
lmtemp$maxtemp <- um(lmtemp$maxtemp)
tbl(lmtemp, fs = 11, 
    caption = "Maximum daily temperature, Umeå 1901--1950.")
```

The next step is to take *minimum* over year and month, see Table \@ref(tab:aver7).

```{r aver7}
atmp <- aggregate(list(temp = mtemp$maxtemp), 
                  by = mtemp[, c("month", "year")], 
                  FUN = min)
hatmp <- head(atmp, 3)
hatmp$temp <- um(hatmp$temp)
tbl(hatmp, fs = 11, 
    caption = "Average daily max temperature by month, Umeå 1901--1950.")
```

Now we can apply `make.communal` to our data and split spells *by year and month*. 
The result is shown in Table \@ref(tab:makecom7).

```{r makecom7, cache = TRUE}
atmp$yearmonth <- atmp$year * 100 + atmp$month 
## A trick to get format 190101
comtime <- system.time(
    nt <- make.communal(ume, atmp["yearmonth"], 
                        start = 1901, period = 1/12))

nt$enter <- round(nt$enter, 3)
nt$exit <- round(nt$exit, 3)
oj <- nt$enter >= nt$exit - 0.0001 # Too short interval!
nt$enter[oj] <- nt$exit[oj] - 0.001  # Break accidental ties
nt$year <- nt$yearmonth %/% 100 # Restore 'year'.
nt$month <- nt$yearmonth %% 100 # Restore 'month'.
saveRDS(nt, file = "mytables/nt.rds")
nt <- nt[nt$month %in% c(12, 1, 2), ]
tbl(head(nt[, -8], 3), fs = 10, 
    caption = "Population data by year and month, Umeå 1901--1950.")
```

Total time for *making communal*: 25 seconds.


The next step is to read temperature from `atmp` to `nt`, see 
Table \@ref(tab:readtmp7) (selected variables).

```{r prepreadtmp7, echo = TRUE}
indx <- match(nt$yearmonth, atmp$yearmonth)
nt$temp <- atmp$temp[indx]
```

```{r readtmp7, echo = FALSE}
xx <- head(nt[, c("id", "sex", "enter", "exit", "event", "year", "month", "socStatus", "temp")], 3)
xx$temp <- um(xx$temp)
tbl(xx, fs = 10, caption = "Temperature added to Umeå data.")
```

This data frame contains `r NROW(nt)` records, maybe too much for a comfortable 
Cox regression. Let's see what happens (Table \@ref(tab:coxph7)):

```{r coxph7, cache = TRUE, results = 'asis'}
ptm <- proc.time()
fit <- coxreg(Surv(enter, exit, event) ~ 
                  sex + socStatus + temp, data = nt)
ctime <- proc.time() - ptm
fit.out(fit, label = "coxph7", 
        caption = "Mortality and temperature, Umeå 1901--1950.")
```

This is quite bad (the computing time,  almost 2 minutes), 
but we already have a substantial result: 
Survival chances *increase* with temperature. But remember that Umeå 
is a northern town, not much warm weather here. And further, no signs of 
interactions with sex or social status (not shown). 

<!--
But it can also be the case that both
high and low temperatures are critical, which may motivate the categorization of 
temperature. Let us look at its distribution over the year.

```{r temphist, fig.cap = "Monthly minimum  temperatures, Umeå 1901-1950.", eval = FALSE}
hist(atmp$temp, xlab = "Temperature (centigrade)", main = "")
```

And the winter distribution:

```{r temphist1, fig.cap = "Monthly minimum  temperatures, Umeå 1901-1950. October-March.", eval = FALSE}
hist(atmp[atmp$month %in% c(1:3, 10:12), ]$temp, 
     xlab = "Temperature (centigrade)", main = "")
```

And in the summer:

```{r temphist2, fig.cap = "Monthly minimum  temperatures, Umeå 1901-1950. April-September.", eval = FALSE}
hist(atmp[atmp$month %in% c(4:9), ]$temp, 
     xlab = "Temperature (centigrade)", main = "")
```


Winter survival analysis results, with cut points at -20, -5 degrees Celsius:

```{r catetemp1, cache = TRUE, eval = FALSE}
nt$ctemp <- cut(nt$temp, breaks = c(-30, -20, -5, 5))
fit <- coxreg(Surv(enter, exit, event) ~ sex + ctemp, 
              data = nt[nt$month %in% c(1:3, 10:12), ])
s1fit73 <- summary(fit)
saveRDS(s1fit73, file = "mytables/s1fit73.rds")
##s1fit73 <- readRDS("mytables/s1fit73.rds")
tbl(regtable(s1fit73))
```
Obviously, mortality increases with decreasing temperature, but there is not much 
difference between the two coldest intervals: Clearly best is a temperature around the freezing point. 

Summer results with cut points 0, 10 degrees Celsius:

```{r catetemp2, cache = TRUE, eval = FALSE}
nt$ctemp <- cut(nt$temp, breaks = c(-20, 0, 10, 17))
fit <- coxreg(Surv(enter, exit, event) ~ sex + ctemp, 
              data = nt[nt$month %in% c(4:9), ])
s2fit73 <- summary(fit)
saveRDS(s2fit73, file = "mytables/s2fit73.rds")
##s1fit73 <- readRDS("mytables/s1fit73.rds")
tbl(regtable(s2fit73))
```

Also here is it clear that the months with the highest min temperature are the healthiest.



### Reducing the size of the data set

-->

The analyses so far are very rudimentary, including all ages in one and so on. 
Here we show how extract small subsets of the full data set by some simple and 
reasonable assumptions. It builds on *categorical covariates* and an assumption
of *piecewise constant hazards*. We use the function `toTpch` in the `eha` package,
see Table \@ref(tab:tabulate7).

```{r tabulate7}
told <- toTpch(Surv(enter, exit, event) ~ sex + socStatus + 
                   yearmonth, 
               data = nt, cuts = seq(15, 100, by = 5))
indx <- match(told$yearmonth, atmp$yearmonth)
told$temp <- atmp$temp[indx]
saveRDS(told, file = "mytables/told73.rds")
##told <- readRDS("mytables/told73.rds")
htold <- head(told, 6)
htold$temp <- um(htold$temp)
htold$age <- en(htold$age)
tbl(htold, fs = 11, 
    caption = "Tabular Umeå 1901--1950 data.")
```

The tabulation reduces the data set from 2.5 million records to 19 thousands. And
computing time accordingly (reduced to a quarter of a second!), without jeopardizing the results, 
see Table \@ref(tab:tabulateres7).

```{r tabulateres7, echo = FALSE, results = 'asis'}
fit <- tpchreg(oe(event, exposure) ~ sex + socStatus + temp, 
               data = told, time = age)
fit.out(fit, label = "tabulateres7", 
        caption = "Temperature and mortality, Umeå 1901--1950. PCH model.")
```

Essentially the same conclusion as in the earlier attempts: Mortality decreases 
with increasing temperature.


### Hot summers in Umeå, 1990--2014

As the next example of combining the use of the function `eha::make.communal` and 
tabulation, the effect of hot summers on mortality 
is examined. Data at hand relate to Umeå during the time period 1990--2014.

Temperature data for different places in Sweden can be downloaded from 
[SMHI (The Swedish Meteorological and Hydrological Institute)](https://www.smhi.se),
data for Umeå is read and presented in Table \@ref(tab:readtemp7).

```{r readtemp7, cache = TRUE, echo = FALSE}
temp <- read.table("Data/umeairport.csv", header = FALSE, 
                   skip = 23, sep = ";")[, 1:3]
names(temp) <- c("day", "hour", "temp")
temp$day <- as.Date(temp$day)
temp$hour <- as.numeric(substr(temp$hour, 1, 2))
temp <- temp[temp$day >= as.Date("1990-01-01") & 
                 temp$day <= as.Date("2014-12-31"), ]
temp$year <- as.numeric(format(temp$day, "%Y"))
temp$month <- as.numeric(format(temp$day, "%m"))
library(kableExtra)
source("~/Documents/EHAR2/R/tbl.R")
htemp <- head(temp, 5)
htemp$temp <- um(htemp$temp)
tbl(htemp, caption = "First rows of temperature data for Umeå 1990--2014.")
```

There are 24 measurements taken every day, with few exceptions, in total 
`r NROW(temp)` values. 

Population data for Umeå are extracted from the [Longitudinal integrated database for health insurance and labour market studies (LISA)](https://www.scb.se). LISA contains information about all Swedes aged 16 and above on 31 December yearly, starting at 1990. See Table \@ref(tab:readpop7).

```{r readpop7, cache = TRUE, echo = FALSE}
library(eha)
source("R/tbl.R")
pop <- readRDS("Data/umepop.rds")
pop <- age.window(pop, c(16, 110))
pop <- cal.window(pop, c(1990, 2015))
tbl(head(pop[, -1]), caption = "First rows of individuals  from Umeå 1990--2014.")
```


```{r avermax, echo = FALSE}
temp$yearmonth <- temp$year + 100 * temp$month
```

Then perform the aggregation, see Table \@ref(tab:aggrtemp7).

```{r aggrtemp7, cache = TRUE, echo = FALSE}
aggrtemp <- aggregate(temp ~ month + year, data = temp, FUN = max) #day temp
aggrtemp$yearmonth <- 100 * aggrtemp$year + aggrtemp$month
hh <- head(aggrtemp[aggrtemp$month %in% 6:8,])
hh$month <- factor(hh$month, labels = c("June", "July", "August"))
tbl(hh, caption = "Aggregated summer temperature data, Umeå 1990--2014.")
```

The next step is to aggregate the population data, but we must first split it by 
month and year, using the function `make.communal`. We  want to keep track of 
year and month, so the simplest way to do it is to use the variable `yearmonth`
in `temp` as our communal covariate. And then read temperature from temp:

```{r putoncom7, cache = TRUE}
compop <- eha::make.communal(pop, aggrtemp["yearmonth"], 
                             start = 1990, period = 1 / 12)
indx <- match(compop$yearmonth, aggrtemp$yearmonth)
compop$temp <- aggrtemp$temp[indx]
compop$year <- compop$yearmonth %/% 100
compop$month <- compop$yearmonth %% 100
```

```{r savecompop7, echo = FALSE}
saveRDS(compop, file = "Data/compop.rds")
```

```{r gruppa7, cache = TRUE}
out <- toTpch(Surv(enter, exit, event) ~ yearmonth + sex, 
              data = compop, 
                   cuts = c(seq(15, 95, by = 5), 110))
indx <- match(out$yearmonth, aggrtemp$yearmonth)
out$temp <- aggrtemp$temp[indx]
```


```{r splityearmonth7, echo = FALSE}
out$month <- out$yearmonth %% 100
out$year <- out$yearmonth %/% 100
##summary(out)
saveRDS(out, file = "Data/out.rds")
```

Then the analysis of female mortality in the ages 80 and above and its dependence 
on high temperature (above 29 degrees Celsius). The July maximum temperatures by year 
are shown in Figure \@ref(fig:julmaxtemp7).

```{r julmaxtemp7, fig.cap = "Maximum temperatures in July by year 1990--2014.", echo = FALSE}
par(las = 1)
with(aggrtemp[aggrtemp$month == 7, ], 
     plot(year, temp, type = "b", ylim = c(20, 32), axes = FALSE, 
          ylab = "Degrees Celsius", xlab = "Year", lty = 3))
axis(1, at = c(1990, 1994, 2003, 2014))
axis(2, at = c(20, 25, 29, 32))
box()
abline(h = 29, lty = 2)
```


```{r julydata7, cache = TRUE, results='asis', echo = FALSE}
out <- readRDS("Data/out.rds")
library(eha)
source("R/fit.out.R")
july <- out[out$month %in% 7 &
                as.numeric(out$age) >= 14, ]
july$age <- factor(july$age)
fit <- tpchreg(oe(event, exposure) ~ I(temp > 29), 
               time = age, data = july[july$sex == "female", ])
fit.out(fit, caption = "Tabular PH analysis, female (age 80+) mortality and high temperature, Umeå 1990--2014.", label = "julydata7")
```

With individual-based data and Cox regression, see Table \@ref(tab:idbascox7).

```{r idbascox7, cache = TRUE, echo = FALSE, results='asis'}
cp7 <- compop[compop$month %in% 7, ]
cp7 <- age.window(cp7, c(80, 110)) # Coordinate with july!
sdt <- system.time(fit <- coxreg(Surv(enter, exit, event) ~ I(temp > 29), 
                 data = cp7[cp7$sex == "female", ]))
fit.out(fit, caption = "Cox regression, female (age 80+ ) mortality and high temperature, Umeå 1990--2014.", label = "idbascox7")
```

The results in the two tables are almost identical, women above 80 years of age are 
vulnerable to extreme temperatures: The risk increases with around 30 per cent (95 per cent confidence interval: from 7 to 77 per cent, quite wide, but a *p*-value of 1 per cent).
